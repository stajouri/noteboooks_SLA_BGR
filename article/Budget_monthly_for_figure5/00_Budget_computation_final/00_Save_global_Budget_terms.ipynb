{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f7b535-70f1-47fa-99bd-e6dc9a2d196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n"
     ]
    }
   ],
   "source": [
    "# BUT: enregister les termes du bilan de salinité: dSdt, ADV (adv_h, adv_v), SFX, RES pour tout le globe. \n",
    "\n",
    "# ------------------------\n",
    "# Les variables à choisir :\n",
    "# ------------------------\n",
    "nexpREF = \"GAI\" # \"AI\" or \"S\"\n",
    "\n",
    "# ------------------------\n",
    "## ----import libraries\n",
    "# ------------------------\n",
    "import os,sys\n",
    "import numpy as np\n",
    "# xarray\n",
    "import xarray as xr\n",
    "\n",
    "from dask.distributed import Client\n",
    "c = Client()\n",
    "\n",
    "# ------------------------\n",
    "# loading data\n",
    "# ------------------------\n",
    "diro = \"/gpfsscratch/rech/cli/uor98hu/BILANS/\"+nexpREF+\"/\" \n",
    "diri=\"/gpfswork/rech/cli/rcli002/eORCA025.L75/eORCA025.L75-I/\"\n",
    "mesh_hgr=xr.open_dataset(diri+'mesh_hgr.nc').squeeze()\n",
    "tmask = mesh_hgr.tmask.rename({'nav_lev':\"deptht\"})\n",
    "tmaskutil = mesh_hgr.tmaskutil\n",
    "\n",
    "e1t = mesh_hgr.e1t.fillna(0)\n",
    "e2t = mesh_hgr.e2t.fillna(0)\n",
    "e2u = mesh_hgr.e2u.fillna(0)\n",
    "e1v = mesh_hgr.e1v.fillna(0)\n",
    "nav_lon =  mesh_hgr.nav_lon\n",
    "nav_lat =  mesh_hgr.nav_lat\n",
    "\n",
    "chunk_size = {\"x\":500,\"y\":500}\n",
    "\n",
    "prefix = \"eORCA025.L75-IMHOTEP\"\n",
    "diridatref=\"/gpfsstore/rech/cli/rcli002/eORCA025.L75/\"+prefix+\".\"+nexpREF+\"-S/\"\n",
    "fo=\"1m\" # frequency used\n",
    "    \n",
    "for year in np.arange(2015,2019):\n",
    "    y1 = str(year)\n",
    "    print(y1)\n",
    "    listTfiles=diridatref+\"/1m/\"+y1+\"/*1m_gridT.nc\"\n",
    "    listUfiles=diridatref+\"/1m/\"+y1+\"/*1m_gridU.nc\"\n",
    "    listVfiles=diridatref+\"/1m/\"+y1+\"/*1m_gridV.nc\"\n",
    "\n",
    "    T_ds = xr.open_mfdataset(listTfiles,decode_coords=True,chunks=chunk_size,parallel=True)\n",
    "    U_ds= xr.open_mfdataset(listUfiles,decode_coords=True,chunks=chunk_size,parallel=True)\n",
    "    V_ds = xr.open_mfdataset(listVfiles,decode_coords=True,chunks=chunk_size,parallel=True)\n",
    "\n",
    "    e3t = T_ds.e3t.fillna(0)\n",
    "    e3u = U_ds.e3u.fillna(0)\n",
    "    e3v = V_ds.e3v.fillna(0)\n",
    "\n",
    "    listProdUfiles = diridatref+\"/1m/\"+y1+\"/*1m_PRODU.nc\"\n",
    "    listProdVfiles = diridatref+\"/1m/\"+y1+\"/*1m_PRODV.nc\"\n",
    "    listProdWfiles = diridatref+\"/1m/\"+y1+\"/*1m_PRODW.nc\"\n",
    "\n",
    "    PRODU_ds = xr.open_mfdataset(listProdUfiles,decode_coords=True,chunks=chunk_size,parallel=True)\n",
    "    PRODV_ds = xr.open_mfdataset(listProdVfiles,decode_coords=True,chunks=chunk_size,parallel=True)\n",
    "    PRODW_ds = xr.open_mfdataset(listProdWfiles,decode_coords=True,chunks=chunk_size,parallel=True)\n",
    "\n",
    "    US_ref = PRODU_ds.vous.fillna(0)\n",
    "    VS_ref = PRODV_ds.vovs.fillna(0)\n",
    "    WS_ref = PRODW_ds.vows.fillna(0)\n",
    "\n",
    "    # ------------------------\n",
    "    # time tendency: dSdt\n",
    "    # ------------------------\n",
    "\n",
    "    dSdt1darr = np.zeros((12,75,1207,1442))\n",
    "    nbsec = np.zeros((12))\n",
    "\n",
    "    i = 0\n",
    "    for month in ['01','02','03','04','05','06','07','08','09','10','11','12']:\n",
    "        file = diridatref+\"/1d/\"+y1+\"-concat\"+\"/eORCA025.L75-IMHOTEP.\"+nexpREF+\"_y\"+y1+\"m\"+month+\"_1d_gridT.nc\"\n",
    "        ds_T1d = xr.open_dataset(file,chunks = {\"time_counter\":2,\"deptht\":5}).squeeze()\n",
    "        S1d = ds_T1d.vosaline\n",
    "        deltat1d = (S1d.time_counter[-1].values - S1d.time_counter[0].values)*1e-9 + 86400 ## nombre de secondes dans le mois\n",
    "        dSdt1d = (S1d[-1] - S1d[0]) / float(deltat1d)\n",
    "        nbsec[i] = float(deltat1d)\n",
    "        dSdt1d = dSdt1d.compute()\n",
    "        dSdt1darr[i,:,:,:]=dSdt1d.values\n",
    "        i+=1\n",
    "\n",
    "    # convert into dataset \n",
    "    dsdSdt1d = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            dSdt=([\"time_counter\",\"deptht\",\"y\", \"x\"], dSdt1darr),\n",
    "            nbsec=([\"time_counter\"], nbsec)),\n",
    "        coords=dict(\n",
    "            time_counter=WS_ref.time_counter.values,\n",
    "            deptht=e3t.deptht.values,\n",
    "            nav_lat=([\"y\", \"x\"], nav_lat.values),\n",
    "            nav_lon=([\"y\", \"x\"], nav_lon.values)),\n",
    "        attrs=dict(\n",
    "            description=\"dS/dt for each mont using daily snapshots\",\n",
    "            units=\"10-3/s\")\n",
    "        )\n",
    "\n",
    "    # saving\n",
    "    dsdSdt1d.to_netcdf(path = diro+nexpREF+\"_dSdt_1m\"+str(y1)+\".nc\", mode='w')\n",
    "\n",
    "\n",
    "    # ------------------------\n",
    "    # calcul de l'advection horizontale\n",
    "    # ------------------------\n",
    "    # manuel NEMO 4.0.1 §4.1.\n",
    "    bt = (e3t*e1t*e2t) # volume of each cell\n",
    "\n",
    "    prod1_U = (e3u * US_ref * e2u)\n",
    "    prod1_V = (e3v * VS_ref * e1v)\n",
    "\n",
    "    deltaU = (prod1_U - prod1_U.roll(x=1)) # garder en tete que le premier point est pas bon\n",
    "    deltaV = (prod1_V - prod1_V.roll(y=1)) # garder en tete que le premier point est pas bon\n",
    "\n",
    "    DIV = ( deltaU.rename({'depthu':'deptht'}) + deltaV.rename({'depthv':'deptht'}) ).where(tmask)\n",
    "    DIV = DIV * tmaskutil * (-1)\n",
    "    adv_h = DIV/bt\n",
    "    adv_h = adv_h.compute()\n",
    "    dsadv_h = adv_h.to_dataset(name = 'adv_h')\n",
    "\n",
    "    # saving\n",
    "    dsadv_h.to_netcdf(path=diro+nexpREF+\"_adv_h_1m\"+str(y1)+\".nc\", mode='w')\n",
    "\n",
    "    # ------------------------\n",
    "    # calcul de l'advection verticale\n",
    "    # ------------------------\n",
    "    deltaW = -(WS_ref.diff(dim = \"depthw\")) # do top - bottom of each cell, we loose the depthw of the top cell, but the \"value\" of the bottom cell. \n",
    "    # arranging e3t depth dimension: putting depthw\n",
    "    e3t4W = e3t.isel(deptht=np.arange(0,74)).assign_coords({\"deptht\":deltaW.depthw.values}).rename({'deptht':'depthw'})\n",
    "    adv_v = deltaW/e3t4W # we divide by the e3t cell thickness corresponding to the cell top - bottom\n",
    "    adv_v = adv_v.rename({'depthw':'deptht'}).assign_coords({\"deptht\":e3t.deptht[:74].values})\n",
    "    #adv_v : ajouter une couche au fond = 0\n",
    "    adv_varr = np.zeros((12,75,1207,1442))\n",
    "    adv_varr[:,0:74,:,:] = adv_v.values\n",
    "\n",
    "    # convert to dataArray\n",
    "    adv_vda  = xr.DataArray(\n",
    "        data=adv_varr,\n",
    "        dims=[\"time_counter\",\"deptht\", \"y\", \"x\"],\n",
    "        coords=dict(\n",
    "            time_counter=WS_ref.time_counter.values,\n",
    "            time_centered = ([\"time_counter\"],adv_h.time_centered.values),\n",
    "            deptht=e3t.deptht.values,\n",
    "            nav_lat=([\"y\", \"x\"], nav_lat.values),\n",
    "            nav_lon=([\"y\", \"x\"], nav_lon.values)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    adv_v = adv_vda.where(tmask) \n",
    "    adv_v = adv_v * tmaskutil * (-1)\n",
    "    dsadv_v = adv_v.to_dataset(name = 'adv_v')\n",
    "\n",
    "    #saving\n",
    "    dsadv_v.to_netcdf(path=diro+nexpREF+\"_adv_v_1m\"+str(y1)+\".nc\", mode='w')\n",
    "\n",
    "    # ------------------------\n",
    "    # calcul de l'advection totale\n",
    "    # ------------------------\n",
    "    ADV = adv_h + adv_v\n",
    "    dsADV = ADV.to_dataset(name = 'adv')\n",
    "    dsADV.to_netcdf(path=diro+nexpREF+\"_adv_1m\"+str(y1)+\".nc\", mode='w')\n",
    "\n",
    "    # ------------------------\n",
    "    # calcul du flux de sel de surface\n",
    "    # ------------------------\n",
    "    listflxTfiles=diridatref+\"/1m/\"+y1+\"/*1m_flxT.nc\"\n",
    "    flxT_ds = xr.open_mfdataset(listflxTfiles,decode_coords=True,chunks=chunk_size,parallel=True)\n",
    "    sfxvar = flxT_ds.sosfldow\n",
    "\n",
    "    SFX = (sfxvar)/(e3t[:,0,:,:]*(-1000))\n",
    "    SFXds = SFX.to_dataset(name = 'sfx')\n",
    "    SFXds.to_netcdf(path=diro+nexpREF+\"_sfx_1m\"+str(y1)+\".nc\", mode='w')\n",
    "\n",
    "    # ------------------------\n",
    "    # calcul du RHS : ADV + SFX\n",
    "    # ------------------------\n",
    "    SFXarr = np.zeros((12,75,1207,1442))\n",
    "    SFXarr[:,0,:,:] = SFX.values\n",
    "\n",
    "    SFXda  = xr.DataArray(\n",
    "        data=SFXarr,\n",
    "        dims=[\"time_counter\", \"deptht\", \"y\", \"x\"],\n",
    "        coords=dict(\n",
    "            time_counter=e3t.time_counter.values,\n",
    "            deptht=e3t.deptht.values,\n",
    "            nav_lat=([\"y\", \"x\"], nav_lat.values),\n",
    "            nav_lon=([\"y\", \"x\"], nav_lon.values))\n",
    "        )\n",
    "\n",
    "    rhs = ADV + SFXda\n",
    "\n",
    "    rhsds = rhs.to_dataset(name = 'rhs')\n",
    "    rhsds.to_netcdf(path=diro+nexpREF+\"_rhs_1m\"+str(y1)+\".nc\", mode='w')\n",
    "\n",
    "    # ------------------------\n",
    "    # calcul du Résidu\n",
    "    # ------------------------\n",
    "    res = dsdSdt1d.dSdt - rhs\n",
    "    resds = res.to_dataset(name = 'res')\n",
    "    resds.to_netcdf(path=diro+nexpREF+\"_res_1m\"+str(y1)+\".nc\", mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418e32e-da29-4e21-ada5-199549b0e70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
